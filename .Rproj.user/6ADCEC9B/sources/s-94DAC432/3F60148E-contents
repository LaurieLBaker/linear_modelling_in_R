---
title: "Introduction to Linear Modelling"
subtitle: "Data Science Campus"  
author: "Dr. Laurie Baker"
institute: "@llbaker1707"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    lib_dir: libs
    seal: false
    css: xaringan-themer2.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      ratio: 16:9
editor_options: 
  chunk_output_type: console
---

```{r libraries, results='hide', message = FALSE, echo = FALSE,  warning = FALSE}

#install.packages("tidyverse")
#install.packages("readxl")
#devtools::install_github("gadenbuie/xaringanExtra")



library(tidyverse)
library(readxl)
library(lubridate)
library(xaringanExtra)
library(fontawesome)

knitr::opts_chunk$set(out.width = "75%",
                      message=FALSE, warning=FALSE, cache = TRUE, 
                      autodep = TRUE, hiline=TRUE)


xaringanExtra::use_editable(expires = 1)

xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)

xaringanExtra::use_clipboard()

xaringanExtra::use_share_again()
xaringanExtra::style_share_again(share_buttons = c("twitter", "linkedin", "pocket"))

```



class: title-slide, center, bottom


# `r rmarkdown::metadata$title`


```{r, echo=FALSE, out.width=550, fig.align='center'}

knitr::include_graphics("images/tidydata_5.jpg")

```


## `r rmarkdown::metadata$subtitle`



### `r rmarkdown::metadata$author`



### `r rmarkdown::metadata$date`




---

# You

* Are familiar with R. 

* Are new to linear modelling or haven't covered it in a while.

* Are new to linear modelling in R.


```{r, echo=FALSE, out.width=600, fig.align='center'}

knitr::include_graphics("images/tidydata_5.jpg")

```
Artwork by @allison_horst

---
# Getting started


* For this adventure you'll need the `tidyverse` meta-package, `broom` to tidy our models, and `GGally` to plot our coefficients.

```{r packages, eval = FALSE}

#install.packages(tidyverse)
#install.packages(broom)
#install.packages(GGally)

library(tidyverse)
library(broom)
library(GGally)

```

* And we'll be working with the data.frame `faculty_salaries.csv`.


---
class: inverse, middle, center


# Exploratory Data Analysis



---

#  Learning Objectives

*  What is the difference between a continuous and categorical variable?

--

*  What is variation and covariation?

--

*  Where does Exploratory Data Analysis fit in with analysis?

--

*  How to use plots to explore variation in 
    *	A continuous variable
    *	A categorical variable
--

* How to use plots to explore covariation between
    *	Two continuous variables
    *	A categorical and continuous variable. 


---

##  `r fa(name = "question-circle")` Continuous or Discrete?

```{r, echo=FALSE, out.width=550, fig.align='center'}

knitr::include_graphics("images/continuous_discrete.png")

```
Artwork by @allison_horst

`r fa(name = "brain")` Discrete variables are **nominal** if they have no order and **ordinal** if there is an order

???
  - A `Categorical variable` is
  
        - `nominal` if they have no order (e.g. 'Ghana' and 'Uruguay')
        
        - `ordinal` if there is an order associated with them (e.g. 'low', 'medium', and 'high')
  

---

# Read in the data

```{r salaries, eval = TRUE}

salaries <- read_csv("../data/faculty-data.csv")

salaries <- salaries %>%
              mutate(department = as_factor(department))

```
---

## Explore the data

`r fa(name = "question-circle")` What are the variables in our data set?

```{r}

head(salaries)

```


---
## Explore the data

`r fa(name = "question-circle")`  How many departments are in the data? 

`r fa(name = "question-circle")` How many employees are in each department?

```{r}

summary(salaries)

```

`r fa(name = "question-circle")` What does each row in the data.frame represent?

```{r, eval = FALSE}

#View(______)

```

---
## Exercise

`r fa(name = "question-circle")`  Which variables are continuous?

.can-edit.con_var[
- ?
- ?
- ?
- ?
]

`r fa(name = "question-circle")`  Which variables are categorical (discrete/factor)?

.can-edit.cat_var[
- ?
- ?
- ?
- ?
]

`r fa(name = "question-circle")`  Are they nominal or ordinal?
---

##  What is variation and covariation?

- `Variation`: is the tendency of values of a variable to change from measurement to measurement.  

--

- `Covariation`: tendency of values of a variable to change with the values of another variable.


???

Introduce the slide: Now we know more about the structure of our data we can explore the variation and covariation in the variables. Knowing the variation and covariation between variables can help us to understand the spread of the data and potential relationships in the data that may give insight into modelling.  

Lead in to the next slide: Visualisation is a great initial tool to explore these relationships further. How you visualise this variation depends on whether the variable is categorical or continuous?


---

## Where does Exploratory Data Analysis fit in with analysis?


- Hypothesis generation

--

- Data exploration

--

- Formal statistical testing

---
class: inverse, middle, center

# Using plots to explore variation and covariation


---

# Single continuous variable


.left-code[

```{r first-plot1a, eval=FALSE}
ggplot(data = salaries) +
   geom_density(aes(salary), fill = "blue")

```
]

.right-plot[
```{r first-plot1a, ref.label='first-plot1a', echo=FALSE, out.width="75%"}
```
]

---
# Single categorical variable

.left-code[

```{r first-plot2a, eval=FALSE}

ggplot(data = salaries) +
   geom_bar(aes(x = department, fill = department)) +
   labs(x = "Department", y = "# Staff", fill = "Department")
  

```
]

.right-plot[
```{r first-plot2a, ref.label='first-plot2a', echo=FALSE, out.width="75%"}
```
]

---
# Two continuous variables

.left-code[

```{r first-plot3a, eval=FALSE}

ggplot(data = salaries) +
  geom_point(aes(x = experience, y = salary, color = department))

```
]

.right-plot[
```{r first-plot3a, ref.label='first-plot3a', echo=FALSE, out.width="75%"}
```
]



---
# Two continuous variables



* **positive relationship** as one variable increases the other variable increases

--

* **negative relationship** as one variable increases the other decreases

--

* **no relationship** no discernable pattern of change in one variable with the other.

--

* **non-linear relationship** we may also be able to pick out other patterns, e.g. *polynomials*. 

???


Plotting two continuous variables, we can see how they change in relation to each other. 


---
# Do salaries increase with experience?

.left-code[

```{r first-plot4a, eval=FALSE}

ggplot(data = salaries) +
  geom_point(aes(x = experience, y = salary, color = department))

```
]

.right-plot[
```{r first-plot4a, ref.label='first-plot4a', echo=FALSE, out.width="75%"}
```
]



---
# A discrete and continuous variable

.left-code[

```{r first-plot5a, eval=FALSE}

ggplot(data = salaries) +
  geom_boxplot(aes(x = department, y = salary, color = department))

```
]

.right-plot[
```{r first-plot5a, ref.label='first-plot5a', echo=FALSE, out.width="75%"}
```
]



???

* A box plot gives us a visual representation of the distribution of numeric data using quartiles. It can be a good way to see how the data is spread and to identify potential outliers. 
    * The box plot shows the median (second quartile) in the middle of the plot.
    * The first and third quartile represent the interquartile range (25\% to 75\%). 
    * The minimum and maximum are defined as the (Q1 - 1.5 x IQ) and (Q3 + 1.5 x IQ).


---
# A discrete and continuous variable


.left-code[

```{r first-plot6a, eval=FALSE}

ggplot(data = salaries) +
  geom_violin(aes(x = department, y = salary, fill = department))

```
]

.right-plot[
```{r first-plot6a, ref.label='first-plot6a', echo=FALSE, out.width="75%"}
```
]

--

`r fa(name = "question-circle")` Which departments have the highest salaries? 

--

`r fa(name = "question-circle")` Do you think the departments are very different from one another?


---
class: inverse, middle, center

# Model Basics and Construction

---

# Learning objectives

* What is a model family and fitted model?

--

* What is the difference between a response and an explanatory variable?

--

* How to construct a linear model in R.

--

* What are the slope and intercept in a linear model?

--

* Picking out key information from the model table

--

* How to extract specific parameters from the model object

---
## Model families and fitted models

A goal of models is to partition data into **patterns** and **residuals**.

1. **Family of models:**
    * Express precise, but generic pattern you wish to capture. 
    * E.g., a straight line $y = ax + b$ or quadratic curve $y = ax^2 + bx + c$. 
--

2. **Fitted model**
    * The **model family** is expressed as an equation.
    * In model fitting, the different parameters are able to take on different values to **adjust** the shape of the **fitted line** to the data.
    
--
    * N.B. The fitted model is just the closest model from a family of models. 
 

???

* Ideally your model will 
    * capture **signals** (i.e. patterns)
    * and ignore **noise** (i.e. random variation).
 
A goal of models is to partition data into **patterns** and **residuals**.

There are two key parts to a model:

1. Family of models:
  * define a family of models that express precise, but generic pattern you wish to capture. For example, a straight line $y = ax + b$ or quadratic curve $y = ax^2 + bx + c$. Where $x$ and $y$ are known variables from your data, and $a$, $b$, and $c$ are parameters that can vary to capture different patterns. 

2. Fitted model
    * After you've chosen your model family, the next step is to generate a fitted model from that family that is closest to your data. 
    * the **model family** is expressed as an equation, where the different parameters are able to take on different values to adjust the shape of the fitted line to the data.

N.B. The fitted model is just the closest model from a family of models. 

---
## Model families and fitted analogy


<img src="images/clothesline.jpg" height="300px" />
<img src="images/tailor_fit.jpg" height="300px" />

* Models are garments and fitting models is like tailoring.

???

If we use clothes as an analogy, the family of models is like an assortment of garments you could choose to 'clothe' the data in. Just as some clothes will be more suitable than others depending on what you wish to do (e.g. nice dress to a wedding), the same is true for models. The type of model will depend on the type of data you have and what you wish to do with your analysis. 

Model fitting is similar to getting a garment tailored. Just as you might make alterations to improve the fit of a garment, you will adapt the chosen model to get a better fit to the data. 




---
## What is the difference between a response and an explanatory variable?


 * **Response variable**: the measured variable you are trying to explain
      * `Dependent`, `target` (machine learning) 
      
--

 * **Explanatory variables**: measured variables that we use to try to explain the response variable. 
      * `Independent`, `features` (machine learning)

--

* Generally the response variable is shown on the y axis. 

???

In the field of data science you will see a number of terms used to refer to the same things. Here, we will use `response variable` to refer to the measured variable you are trying to explain. We will use `explanatory variables` to refer to the measured variables that we use to try to explain the response variable. Other terms that you may come across for these concepts include:
 * **response variable**: `dependent`, `target` (machine learning) 
 * **explanatory variables**: `independent`, `features` (machine learning)

---
## Linear Models

Linear models take the mathematical form:

$y = ax + b$

  * $y$ is the response variable 
  * $a$ is the slope 
  * $x$ is an explanatory variable
  * $b$ is the intercept.


???

Linear regression is one of the most important and widely used regression techniques. Its main advantage is its simple structure and ease of interpreting results.

---
## Linear Models

a and b are generally denoted by regression parameters $\hat{\beta_{0}}$ and $\hat{\beta_{1}}$. The $\hat{}$ indicates that these are estimated.


$$\hat{y_{i}} = \hat{\beta_{0}}+\hat{\beta_{1}}x_{i}+\epsilon_{i}$$
Notation:

--

* $\hat{y_{i}}$ is the response variable.

--

* $\hat{\beta_{0}}$ is the intercept of the line that best fits the data.

--

* $\hat{\beta_{1}}$ is the slope of the line that best fits the data.

--

* $x_{i}$ is the explanatory variable.

--

* $\epsilon_{i}$ is the error term.

--
* $_i$ subscript indicating that the value can vary across cases/individuals/observations.



---
# Three different hypotheses

1. Starting salary and the rate at which salaries increase is the **same**.

--

2. Starting salary **differs** by department, but the rate at which salaries increase in the **same**.

--

3. Starting salary **differs** by department and the rate at which salaries increase is **different**. 

---
# Hierarchical model animation

<iframe src="http://mfviz.com/hierarchical-models/" width="95%" height="90%" frameBorder="0"></iframe>
---
class: inverse, middle, center

# Starting salary and the rate at which salaries increase is the **same**.

---
## How to construct a linear model in R?

Form:

```{r, eval = FALSE}

m1 <- lm(y ~ x, data = df)

m1 <- lm(y ~ x1 + x2 + x3, data = df)

```

--
* Our hypothesis: starting salary and the rate at which salaries increase is the **same**.


* What are our response and explanatory variables in this case?

--

```{r}

m1 <- lm(salary ~ experience, data = salaries)

```



--


$$salary_{i}=\hat{\beta_{0}}+\hat{\beta_{1}}experience_{i}+\epsilon_{i}$$

---
class: inverse, middle, center

# Assessing Model Fit

---

# Learning Objectives

* How to pick out key information from the table from a fitted model.

--

* How to inspect model residuals to assess model fit?

--

* How to use Adjusted R-squared and AIC to compare models.

---
# Picking out key information



```{r, size = "small"}
summary(m1)
```
--

* **Intercept interpretation:** the starting salary is 62154 USD.

* **Slope interpretation:** with every year of experience an employee's salary increases by 683.5 USD. 
* **Amount of variation explained:** Overall the model is a poor fit, with only 0.01235 percent of the variation explained by the model as shown by the Adjusted R-squared.

???


The summary gives us a range of diagnostic information about the model we’ve fitted:

* **Call:** This is an R feature that shows what function and parameters were used to create the model.

* **Residuals:** difference of the observed value and the predicted value.

* **Estimate:** coefficient estimates for the intercept and explanatory variables.

* **Std Error:** standard errors (i.e. an estimate of the uncertainty) of the coefficient estimates.

* **t value**: t-statistic for the t-test comparing whether the coefficient is different to 0.

* **Pr(>|t|):** p-value for the t statistics, giving the significance of coefficient.

* **Residual standard error:** an expression of the variation of the observations around the regression line.

* **Multiple R-squared/Adj. R-squared:**  The proportion of the variance in the observed values explained by the model. The Adj. R-squared takes into account the number of variables in the model.

* **F-statistic, p-value:** Model fit info (allow you to compare different models to assess the best one)


---
# Extracting the fitted model

Getting the fitted model.

```{r}

m1_results <- broom::augment(m1)


head(m1_results)
```

---
#  Plotting the fitted model


.left-code[

```{r first-plot7a, eval=FALSE, warning = FALSE, message = FALSE}


ggplot(data = m1_results,
       aes(x = experience, y = salary)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE)

```
]

.right-plot[
```{r first-plot7a, ref.label='first-plot7a', echo = FALSE, out.width="65%"}
```
]

---
# The Residuals


```{r, echo=FALSE, out.width=580, fig.align='center'}

knitr::include_graphics("images/dragon_residual.png")

```
Artwork by @allison_horst

---
# The Residuals

.left-code[

```{r first-plot8a, eval=FALSE, warning = FALSE, message = FALSE}

ggplot(data = m1_results,
       aes(x = experience, 
           y = salary)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  geom_segment(aes(xend = experience, 
                   yend = .fitted), 
               color = "red", 
               size = 0.3)


```
]

.right-plot[
```{r first-plot8a, ref.label='first-plot8a', echo=FALSE, out.width="65%"}
```
]

???


Remember: The goal of models is to partition data into **patterns** and **residuals**.

---

# Inspecting model residuals

The diagnostic plots show residuals in four different ways:

* **Residuals vs Fitted:** is used to check the assumptions of linearity. If the residuals are spread equally around a horizontal line without distinct patterns (red line is approximately horizontal at zero), that is a good indication of having a linear relationship.

--

* **Normal Q-Q:** is used to check the normality of residuals assumption. If the majority of the residuals follow the straight dashed line, then the assumption is fulfilled.

--

* **Scale-Location:** is used to check the homoscedasticity of residuals (equal variance of residuals). If the residuals are spread randomly and the see a horizontal line with equally (randomly) spread points, then the assumption is fulfilled. 

--

* **Residuals vs Leverage:** is used to identify any influential value in our dataset. Influential values are extreme values that might influence the regression results when included or excluded from the analysis. Look for cases outside of a dashed line. 

---
## Residuals vs Fitted

.left-code[

```{r first-plot9a, eval=FALSE, warning = FALSE}


plot(m1, 1)


```
* **Residuals vs Fitted:** If the residuals are spread equally around a horizontal line without distinct patterns (red line is approximately horizontal at zero), that is a good indication of having a linear relationship.

]

.right-plot[
```{r first-plot9a, ref.label='first-plot9a', echo=FALSE, out.width="75%"}
```
]


---
## Normal Q-Q


.left-code[

```{r first-plot10a, eval=FALSE, warning = FALSE}


plot(m1, 2)


```
* **Normal Q-Q:**  If the majority of the residuals follow the straight dashed line, then the assumption is fulfilled.

]

.right-plot[
```{r first-plot10a, ref.label='first-plot10a', echo=FALSE, out.width="75%"}
```
]

---
## Scale-Location


.left-code[

```{r first-plot11a, eval=FALSE, warning = FALSE}


plot(m1, 3)


```

* **Scale-Location:** If the residuals are spread randomly and the see a horizontal line with equally (randomly) spread points, then the assumption is fulfilled. 

]

.right-plot[
```{r first-plot11a, ref.label='first-plot11a', echo=FALSE, out.width="75%"}
```
]

```{r}

plot(m1, 3)

```


---
# Residuals vs Leverage

.left-code[

```{r first-plot12a, eval=FALSE, warning = FALSE}


plot(m1, 4)


```

* **Residuals vs Leverage:** is used to identify any influential value in our dataset. Look for cases outside of a dashed line. 
]

.right-plot[
```{r first-plot12a, ref.label='first-plot12a', echo=FALSE, out.width="75%"}
```
]




---
class: inverse, middle, center

# Starting salary **differs** by department, but the rate at which salaries increase in the **same**.

---
# Plotting the data

.left-code[

```{r first-plot13a, eval=FALSE, warning = FALSE}


ggplot(data = salaries) +
  geom_point(aes(x = experience, 
                 y = salary, 
                 color = department)) +
  labs(x="Experience", y="Salary") +
  scale_colour_discrete('Department')



```

* Our data is "nested", that is we have groups within our data. We can add group, the department, as a third variable as the colour.

]

.right-plot[
```{r first-plot13a, ref.label='first-plot13a', echo=FALSE, out.width="75%"}
```
]


---
# Constructing the Linear Model

* How does the formula change if we think each group may have a different starting salary?

--

```{r}
m2  <- lm(salary ~ experience + department, data = salaries)

```

--
```{r}

m2_results <- broom::augment(m2)
```

---
# Plotting the fitted model

.left-code[

```{r first-plot14a, eval=FALSE, warning = FALSE}


ggplot(data = m2_results, 
       aes(x = experience, 
           y = salary, 
           colour = department)) +
  geom_point() +
  labs(x="Experience", y="Salary") +
  scale_colour_discrete('Department') +
  geom_line(aes(y = .fitted), size = 1) 


```


]

.right-plot[
```{r first-plot14a, ref.label='first-plot14a', echo=FALSE, out.width="75%"}
```
]


---
# Plotting the fitted model and residuals


.left-code[

```{r first-plot15a, eval=FALSE, warning = FALSE}

ggplot(data = m2_results, 
       aes(x = experience, y = salary, colour = department)) +
  geom_point() +
  labs(x="Experience", y="Salary") +
  scale_colour_discrete('Department') +
  geom_line(aes(y = .fitted), size = 1) +
  geom_segment(aes(xend = experience, yend = .fitted, colour = department), size = 0.3, linetype = 2)

```


]

.right-plot[
```{r first-plot15a, ref.label='first-plot15a', echo=FALSE, out.width="75%"}
```
]

-
# How is the model fit?

```{r}
summary(m2)

```

--

1. Slope Interpretation?
2. Intercept Interpretation?
3. Adjusted $R^2$

---
## Linearity

```{r, echo = FALSE, out.width ="48%"}

plot(m2, 1)

```
---
## Normal QQ


```{r, echo = FALSE, out.width ="48%"}

plot(m2, 2)

```

---
## Scale-Location

```{r, echo = FALSE, out.width ="48%"}
plot(m2, 3)
```

---
# Cook's Distance

```{r, echo = FALSE, out.width ="48%"}
plot(m2, 4)
```

---
## Plotting the coefficients


.left-code[

```{r first-plot16a, eval=FALSE, warning = FALSE}

GGally::ggcoef(m2)

```


]

.right-plot[
```{r first-plot16a, ref.label='first-plot16a', echo=FALSE, out.width="75%"}
```
]


---
# Extracting the coefficients

* Let's extract the residuals using `coef`

```{r}

m2_coef <- coef(m2)

names(m2_coef)

m2_coef

```

---
# Biology vs. Sociology

* If someone works in a department for 6 years, will they have a higher salary if they are in the biology or sociology department?


```{r}

biology_ex6 <- m2_coef["(Intercept)"] + m2_coef["departmentbiology"] + 6*m2_coef["experience"] 


sociology_ex6 <- m2_coef["(Intercept)"] + 6*m2_coef["experience"] 


```

---
# Plotting our predicted values

```{r, eval = FALSE}

m2_results <- broom::augment(m2)

ggplot(data = m2_results, 
       aes(x = experience, y = salary, colour = department)) +
  geom_point() +
  labs(x="Experience", y="Salary") +
  scale_colour_discrete('Department') +
  geom_line(aes(y = .fitted), size = 1) +
  geom_point(aes(x = 6, y = biology_ex6), color = "black") +
  geom_point(aes(x = 6, y = sociology_ex6), color = "black")


```

---
# Plotting our predicted values

```{r, echo = FALSE, out.width = "75%"}

m2_results <- broom::augment(m2)

ggplot(data = m2_results, 
       aes(x = experience, y = salary, colour = department)) +
  geom_point() +
  labs(x="Experience", y="Salary") +
  scale_colour_discrete('Department') +
  geom_line(aes(y = .fitted), size = 1) +
  geom_point(aes(x = 6, y = biology_ex6), color = "black") +
  geom_point(aes(x = 6, y = sociology_ex6), color = "black")


```

---

class: inverse, middle, center

#  Starting salary **differs** by department and the rate at which salaries increase is **different**. 

---
# Constructing the model

How do we include a random slope?


```{r}

m3 <- lm(salary ~ experience*department, data = salaries)

m3_results <- broom::augment(m3)

```

---
# Plotting the fitted model



.left-code[

```{r first-plot17a, eval=FALSE, warning = FALSE}

ggplot(data = m3_results, 
       aes(x = experience, y = salary, color = department)) +
  geom_point() +
  labs(x="Experience", y="Salary") +
  scale_colour_discrete('Department') +
  geom_line(aes(y = .fitted), size = 1)


```


]

.right-plot[
```{r first-plot17a, ref.label='first-plot17a', echo=FALSE, out.width="75%"}
```
]

---
# Plotting the fitted model with the residuals

.left-code[

```{r first-plot18a, eval=FALSE, warning = FALSE}

ggplot(data = m3_results, 
       aes(x = experience, y = salary, color = department)) +
  geom_point() +
  labs(x = "Experience", y = "Salary") +
  scale_colour_discrete('Department') +
  geom_line(aes(y = .fitted), size = 1) +
  geom_segment(aes(xend = experience, yend = .fitted, colour = department), size = 0.3, linetype = 2)
```


]

.right-plot[
```{r first-plot18a, ref.label='first-plot18a', echo=FALSE, out.width="75%"}
```
]

---
# Summary of the model


```{r}

summary(m3)

```

---

### Exercises

* Create the four model diagnostic plots. What do you make of the plots?


* **Residuals vs Fitted:** is used to check the assumptions of linearity. If the residuals are spread equally around a horizontal line without distinct patterns (red line is approximately horizontal at zero), that is a good indication of having a linear relationship.

* **Normal Q-Q:** is used to check the normality of residuals assumption. If the majority of the residuals follow the straight dashed line, then the assumption is fulfilled.


* **Scale-Location:** is used to check the homoscedasticity of residuals (equal variance of residuals). If the residuals are spread randomly and the see a horizontal line with equally (randomly) spread points, then the assumption is fulfilled. 

* **Residuals vs Leverage:** is used to identify any influential value in our dataset. Influential values are extreme values that might influence the regression results when included or excluded from the analysis. Look for cases outside of a dashed line. 

---
# Model 3 Residuals

```{r}
par(mfrow = c(1,2))

plot(m3, 1:2)
```
---
# Model 3 Residuals

```{r}
par(mfrow = c(1,2))

plot(m3, 3:4)
```


---
# What is the predicted salary with 7 years of experience in Biology?


```{r}

m3_coefs <- coef(m3)


```

```{r}

## Biology

biology_ex7 <- m3_coefs["(Intercept)"] + m3_coefs["departmentbiology"] + 7*(m3_coefs["experience:departmentbiology"] + m3_coefs["experience"])


```

---
# Exercise

What is the predicted salary for someone with 7 years of experience Sociology?


```{r, eval = FALSE}

sociology_ex7

```


Try plotting both salaries after 7 years on the graph.


```{r, eval = FALSE}

# ggplot(data = m3_results, 
#        aes(x = experience, y = salary, colour = department)) +
#   geom_point() +
#   labs(x="Experience", y="Salary") +
#   scale_colour_discrete("Department") +
#   geom_line(aes(y = .fitted), size = 1) +
#   geom_point(aes(x = ______, y = ______), color = "black") +
#   geom_point(aes(x = _____, y = ______), color = "black")

```
---




* Let's visualise the coefficients


```{r, out.width = "65%"}

GGally::ggcoef(m3)

```


* Which department has the highest raises (biggest slope)?

```{r}

biology_slope <- m3_coefs["experience:departmentbiology"] + m3_coefs["experience"]


```

* Which department has the highest starting salary (biggest intercept)?

```{r, echo = FALSE}

biology_intercept <- m3_coefs["(Intercept)"] + m3_coefs["departmentbiology"]

```

---


## Model Comparison

* How do we decide which model is better?

* The main metrics we will discuss in this course are:

  1. `Adjusted R^2`
  2. `AIC`
  3. `BIC`

* First, we will discuss `parsimony` and `Occam's Razor`

???

So how can we decide which model is better? There are a few metrics we can compare between the model that can be found in the top table. The three main ones we will discuss in this course are the `Adjusted R^2`, `AIC`, and `BIC`. Before getting to these concepts, let's discuss the concept of `parsimony` and `Occam's Razor`.

---
## Occam's razor: law of parsimony

* `Parsimony` (aka `Occam's razor`): 
    * Argument to choose simpler model over complex ones.
--
* **Model selection:** 
    * Complex model must not just be better, but a specified amount better than a simpler model. 

--

* **Practical considerations:**

  * Simple theories are easier to test than complex ones
  * Simple models often do a better job at predicting
  * Simple models require fewer parameters
  
???
`Parsimony` (aka `Occam's razor`) is a general argument for choosing simpler models even though we know the world is complex. Occam's razor says that when presented with competing hypotheses that make the same predictions, we should select the solution with the fewest assumptions. This is to say that all other things being equal, we should prefer a simpler model to a more complex one, especially when the data don't tell a clear story. 

Model selection approaches often go beyond parsimony to say that a more complex model must not be just better than, but a specified amount better than, a simpler model.

There is also a practical element to parsimony; simple theories are easier to test than complex ones. Similarly, simple models often do a better job at predicting. Because a simpler model requires fewer parameters it is also less expensive in terms of time or money to collect the data for it. 




We need to draw the line somewhere: 

As we add more parameters to a model, we necessarily get an increasingly accurate fit to the particular data we have observed (the bias of our predictions decreases), but our precision for predicting future observations decreases as well (the varaince of our predictions increases). 

One way to think about it is that data contain a fixed amount of information; as we estimate more and more parameters we spread the data thinner and thinner. Eventually the gain in accuracy from having more details in the model is outweighed by the loss in precision from estimating the effect of each of those details more poorly.


---
## Model Comparison: Adjusted $R^2$

**Adjusted R^2**

R-squared is a goodness-of-fit measure for linear regression models. 


$\frac{\text{Variance explained by the model}}{ \text{Total variance}}$

It indicates the percentage of the variance in the response variable explained by the explanatory variables. 

---
## Model Comparison: Likelihood

- `likelihood`: probability of observed outcome (i.e. the data) given a particular choice of parameters. 

--

- Maximum likeilhood: used to find the set of parameters **that make the observed data most likely to have occurred**. 

--

```{r, echo=FALSE, out.width=500, fig.align='center'}

knitr::include_graphics("images/likelihood_example.png")
```
Source: Ashan Priyadarshana. [Maximum Likelihood Estimation published on medium](https://medium.com/quick-code/maximum-likelihood-estimation-for-regression-65f9c99f815d.)


???

The `likelihood` is the probability of the observed outcome (i.e. the data) given a particular choice of parameters. For a particular statistical model, maximum likelihood finds the set of parameters *that makes the observed data most likely to have occurred*. That is, we find the set of parameters that makes the likelihood as large as possible.

The diagram above shows what is happening when you are calculating the maximum likelihood. Here, we have a line of best fit, with the estimated values of the response variable $\hat y_{1...n}$ (red dots). The actual values of the response variable (our data), are reperesented by the black dots. The residuals are indicated by the $\epsilon$. These residual is the distance between the actual value of the response variable and the estimated value of the response variable. 

When we are calculating the maximum likelihood, we are looking for the parameters that maximise the likelihood of the data. The horizontal arrows trace up to the normal distribution which represents the fit. The closer to the peak of the distribution the data falls the "more likely" the data is given the parameters. 

For mathematical convience, we often work with the logarithm of the likelihood (the *log-likelihood*) instead of the likelihood. However, the parameters that give the maximum log-likelihood also give the maximum likelihood. 

---
## Model Comparison: Information Criteria

Information criteria are based on the expected distance between a particular model and the "true" model. 

--

* All information-theoretic methods involve finding the model that minimizes some criterion that is the sum of a term based on the likelihood and a *penalty term*.
    * often twice the negative log-likelihood is used.
    * penalty term varies for different information criteria. 

--

* Selecting models based on **information criteria** allows for the comparison of all candidate models at once, provided they are fit to the same data. 

???
**Information criteria** are based on the expected distance between a particular model and the "true" model. All information-theoretic methods reduce to finding the model that minimizes some criterion that is the sum of a term based on the likelihood (usually twice the negative log-likelihood) and a *penalty term* which is different for different information criteria. 

Selecting models based on information criteria allows for the comparison of all candidate models at once, provided they are fit to the same data. If there are missing values in certain variables and not others, the model will exclude these data when fitting by default, so you need to be careful that you are not comparing models which have been fit to different datasets. 

---
## Akaike Information Criterion

The `Akaike Information Criterion`, or AIC, is the most widespread information criterion, and is defined as

$\text{AIC} = -2L + 2k$

- $L$ is the log-likelihood
- $k$ is the number of parameters in the model. 

--

- Small values represent better overall fits
- Adding a parameter with a negligible improvement in fit penalizes the AIC by 2 log-likelihood units.

---
## Some rough guidance for AIC

- Lower values of AIC indicated a better fit to the data regardless of whether they are positive or negative.

--

- E.g. If you have two models with AIC: -213.09, and -289.12. The model with AIC -289.12 is better.

--

- AIC comparisons are only valid for models that are fit to the same response data (i.e. same y)

--

- For AIC, the rule of thumb people generally follow is that improvements of greater than 2 mean we can select the more complicated model.

---
## BIC
- The *Bayesian* information criterion (BIC) is the second most common.

--

- It uses a penalty term of $(log n)k$. 

--

- The BIC is more conservative than the AIC
    - insists on a greater improvement in fit to accept a more complex model.

---
## Approaches to model selection

- Models with multiple parameters and possible interactions between variable lead to a large number of models to try. 

- Two simple approaches to model selection include:

    - **forward selection** (add parameters one at a time to the simplest model)

--

    - **backward selection** (subtract parameters from the most complex model). 


---

# Comparing models using glance()

```{r}

broom::glance(m1)
broom::glance(m2)



```
---

# Comparing models using glance()

```{r}

broom::glance(m2)
broom::glance(m3)


```

???

The summary gives us a range of diagnostic information about the model we've fitted, split into three tables. Here's a quick guide on what is included:

**Top Table - model fit info.**

  * **R-squared/Adj. R-squared** - The proportion of the variance in the response variable ('petal_width') explained by the model. The Adj. R-squared takes into account the number of variables in the model.
  * **No. of Observations** (i.e. measurements of 'petal_width') and  **Df** degrees of freedom (No. of Observations - (1 + No. of variables in the model)).
  * **General info** - date and time that model was run, type of model etc.
  * **Model Fit info** - inc. **F-statistic**, **AIC** and **BIC**, **Log-Likelihood**. They are not meaningful on their own, but allow you to compare different models to assess the best one. 
    
**Middle Table - an important table!**

  * **coef** = coefficient estimates for the intercept and explanatory variables.
  * **std err** = standard errors (i.e. estimate of the uncertainty) of the coefficient estimates.
  * **t** = t-statistic for the t-test comparing whether the coefficient is different to 0.
  * **P>|t|** = p-value for the t statistics, giving significance of coefficient.
  * **[0.025 0.975]** = 95% confidence interval around the coefficient estimate.
    
**Bottom table - Diagnostics**

  * **Jarque-Bera**, **Omnibus**: test normality of residuals.
  * **Cond, No.**: Condition Number, test for multicollinearity.
  * **Durbin-Watson**: test for autocorrelation.



---

class: center, middle

# Thanks!




Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).

The chakra comes from [remark.js](https://remarkjs.com), [**knitr**](http://yihui.name/knitr), and [R Markdown](https://rmarkdown.rstudio.com).

The gorgeous artwork comes from [@allison_horst](https://github.com/allisonhorst/stats-illustrations)
